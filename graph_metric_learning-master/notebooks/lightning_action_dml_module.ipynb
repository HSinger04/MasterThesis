{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example template for defining a system\n",
    "\"\"\"\n",
    "import logging as log\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule#, seed_everything\n",
    "\n",
    "from pytorch_metric_learning import losses, samplers\n",
    "\n",
    "# seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model import agcn, msg3d\n",
    "from graph import ntu_rgb_d\n",
    "from feeders import feeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNDMLModel(LightningModule):\n",
    "    \"\"\"\n",
    "    Sample model to show how to define a template\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        \"\"\"\n",
    "        Pass in parsed HyperOptArgumentParser to the model\n",
    "        :param hparams:\n",
    "        \"\"\"\n",
    "        # init superclass\n",
    "        super(GCNDMLModel, self).__init__()\n",
    "#         self.hparams = hparams\n",
    "\n",
    "        self.batch_size = 4\n",
    "    \n",
    "        self.learning_rate = 0.0001\n",
    "\n",
    "        self.model = agcn.Model(graph=\"graph.ntu_rgb_d.Graph\")\n",
    "        \n",
    "        self.metric_loss = losses.TripletMarginLoss()\n",
    "\n",
    "#     # ---------------------\n",
    "#     # TRAINING\n",
    "#     # ---------------------\n",
    "    def forward(self, x):\n",
    "        embeddings = self.model(x)\n",
    "        return embeddings\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        metric_loss = self.metric_loss(y_hat, y)\n",
    "        output = {\"loss\": metric_loss}\n",
    "        return output\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        metric_loss = self.metric_loss(y_hat, y)\n",
    "        output = {\"loss\": metric_loss}\n",
    "        output = {\"val_loss\", torch.tensor(0)}\n",
    "        return output\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        result = {\"val_loss\": 0}\n",
    "        return result\n",
    "\n",
    "    # ---------------------\n",
    "    # TRAINING SETUP\n",
    "    # ---------------------\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        return whatever optimizers we want here\n",
    "        :return: list of optimizers\n",
    "        \"\"\"\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def __dataloader(self, dataset_type=\"train\"):\n",
    "        data_path = \"/home/raphael/git/graph_metric_learning/\"\n",
    "        \n",
    "        if dataset_type == \"train\":\n",
    "            dataset = feeder.Feeder(data_path=data_path+\"data/ntu/one_shot/train_data_joint.npy\",\n",
    "                                          label_path=data_path+\"data/ntu/one_shot/train_label.pkl\",\n",
    "                                          debug=False)\n",
    "        \n",
    "        elif dataset_type == \"test\":\n",
    "            dataset = feeder.Feeder(data_path=data_path+\"data/ntu/one_shot/val_data_joint.npy\",\n",
    "                                       label_path=data_path+\"data/ntu/one_shot/val_label.pkl\",\n",
    "                                       debug=False)\n",
    "        elif dataset_type == \"samples\":\n",
    "            sample_dataset = feeder.Feeder(data_path=data_path+\"data/ntu/one_shot/sample_data_joint.npy\",\n",
    "                                       label_path=data_path+\"data/ntu/one_shot/sample_label.pkl\",\n",
    "                                       debug=False)\n",
    "        sampler = samplers.MPerClassSampler(dataset.label, m=4, \n",
    "                                            length_before_new_iter=len(dataset))\n",
    "    \n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, sampler=sampler,\n",
    "#                batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "#                pin_memory=False, drop_last=False, timeout=0,\n",
    "#                worker_init_fn=None, *, prefetch_factor=2,\n",
    "#                persistent_workers=False\n",
    "                               )\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        log.info('Training data loader called.')\n",
    "        return self.__dataloader(dataset_type=\"train\")\n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        log.info('Validation data loader called.')\n",
    "        return self.__dataloader(dataset_type=\"test\")\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def sample_dataloader(self):\n",
    "        log.info('Sample data loader called.')\n",
    "        return self.__dataloader(dataset_type=\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNDMLModel(None)\n",
    "\n",
    "# ------------------------\n",
    "# 2 INIT TRAINER\n",
    "# ------------------------\n",
    "trainer = pl.Trainer(\n",
    "    gpus=-1,\n",
    "#     distributed_backend=hparams.distributed_backend,\n",
    "    max_epochs=1,\n",
    "    use_amp=False\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# 3 START TRAINING\n",
    "# ------------------------\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = GCNDMLModel(None)\n",
    "a = modelx.train_dataloader()\n",
    "for batch_ndx in enumerate(a):\n",
    "    print(batch_ndx)\n",
    "#     print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
